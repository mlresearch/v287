---
title: Contrastive Pretraining for Stress Detection with Multimodal Wearable Sensor
  Data and Surveys
abstract: Stress adversely affects mental and physical health and underscores the
  importance of early detection. Some studies have utilized physiological signals
  from wearable sensors and other information to monitor stress levels in daily life.
  Recent studies use self-supervised methods due to the high cost of collecting stress
  labels. However, self-supervised learning using both time series and tabular features
  such as demographics, traits, and contextual information has been understudied.
  Therefore, there is a need to further investigate how a model can be effectively
  trained with different granularity of multimodal data and limited number of labels.
  In this study, we introduce a self-supervised multimodal learning approach for stress
  detection that combines time series and tabular features. Our proposed method presents
  a promising solution for effectively monitoring stress using multimodal data.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang25a
month: 0
tex_title: Contrastive Pretraining for Stress Detection with Multimodal Wearable Sensor
  Data and Surveys
firstpage: 166
lastpage: 178
page: 166-178
order: 166
cycles: false
bibtex_author: Yang, Zeyu and Yu, Han and Sano, Akane
author:
- given: Zeyu
  family: Yang
- given: Han
  family: Yu
- given: Akane
  family: Sano
date: 2025-07-02
address:
container-title: Proceedings of the sixth Conference on Health, Inference, and Learning
volume: '287'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v287/main/assets/yang25a/yang25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
