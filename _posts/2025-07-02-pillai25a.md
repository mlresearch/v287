---
title: 'Beyond Prompting: Time2Lang - Bridging Time-Series Foundation Models and Large
  Language Models for Health Sensing'
abstract: 'Large language models (LLMs) show promise for health applications when
  combined with behavioral sensing data. Traditional approaches convert sensor data
  into text prompts, but this process is prone to errors, computationally expensive,
  and requires domain expertise. These challenges are particularly acute when processing
  extended time series data. While time series foundation models (TFMs) have recently
  emerged as powerful tools for learning representations from temporal data, bridging
  TFMs and LLMs remains challenging. Here, we present Time2Lang, a framework that
  directly maps TFM outputs to LLM representations without intermediate text conversion.
  Our approach first trains on synthetic data using periodicity prediction as a pretext
  task, followed by evaluation on mental health classification tasks. We validate
  Time2Lang on two longitudinal wearable and mobile sensing datasets: daily depression
  prediction using step count data (17,251 days from 256 participants) and flourishing
  classification based on conversation duration (46 participants over 10 weeks). Time2Lang
  maintains consistent inference times regardless of input length, unlike traditional
  prompting methods. The generated embeddings preserve essential time-series characteristics
  such as auto-correlation. Our results demonstrate that TFMs and LLMs can be effectively
  integrated while minimizing information loss and enabling performance transfer across
  these distinct modeling paradigms. This work establishes a foundation for future
  research combining general-purpose large models for complex healthcare tasks.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pillai25a
month: 0
tex_title: 'Beyond Prompting: Time2Lang - Bridging Time-Series Foundation Models and
  Large Language Models for Health Sensing'
firstpage: 268
lastpage: 288
page: 268-288
order: 268
cycles: false
bibtex_author: Pillai, Arvind and Spathis, Dimitris and Nepal, Subigya and Collins,
  Amanda C. and Mackin, Daniel M and Heinz, Michael V. and Griffin, Tess Z and Jacobson,
  Nicholas C. and Campbell, Andrew
author:
- given: Arvind
  family: Pillai
- given: Dimitris
  family: Spathis
- given: Subigya
  family: Nepal
- given: Amanda C.
  family: Collins
- given: Daniel M
  family: Mackin
- given: Michael V.
  family: Heinz
- given: Tess Z
  family: Griffin
- given: Nicholas C.
  family: Jacobson
- given: Andrew
  family: Campbell
date: 2025-07-02
address:
container-title: Proceedings of the sixth Conference on Health, Inference, and Learning
volume: '287'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v287/main/assets/pillai25a/pillai25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
