---
title: 'When Attention Fails: Pitfalls of Attention-based Model Interpretability for
  High-dimensional Clinical Time-Series'
abstract: Attention-based deep learning models are widely used for clinical time-series
  analysis, largely due to their perceived ability to enhance model interpretability.
  However, the reliability, faithfulness, and consistency of attention mechanisms
  as an interpretability tool in high-dimensional clinical time series data require
  further investigation. We conducted a comprehensive evaluation of consistency and
  faithfulness of attention mechanisms in deep learning models applied to high-dimensional
  clinical time-series data. Specifically, we trained 1000 different variants of an
  attention-based LSTM model architecture with random initializations to analyze the
  consistency of attention scores across mortality prediction and patient severity
  group classification. Our findings revealed significant inconsistencies in attention
  scores for individual samples across the thousand model variants. Visual inspection
  of attention weight distributions indicated that the attention mechanism did not
  consistently focus on the same feature-time pairs, challenging the assumption of
  faithfulness and reliability in model interpretability. The observed inconsistencies
  in per-sample attention weights suggest that attention mechanisms are unreliable
  as an interpretability tool for clinical decision-making tasks involving high-dimensional
  time-series data. While attention mechanisms may enhance model performance metrics,
  they often fail to produce clinically meaningful and consistent interpretations,
  limiting their utility in healthcare settings where transparency is critical for
  informed decision-making.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yadav25a
month: 0
tex_title: 'When Attention Fails: Pitfalls of Attention-based Model Interpretability
  for High-dimensional Clinical Time-Series'
firstpage: 289
lastpage: 305
page: 289-305
order: 289
cycles: false
bibtex_author: Yadav, Shashank and Subbian, Vignesh
author:
- given: Shashank
  family: Yadav
- given: Vignesh
  family: Subbian
date: 2025-07-02
address:
container-title: Proceedings of the sixth Conference on Health, Inference, and Learning
volume: '287'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 7
  - 2
pdf: https://raw.githubusercontent.com/mlresearch/v287/main/assets/yadav25a/yadav25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
